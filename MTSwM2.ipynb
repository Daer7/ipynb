{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTSwM2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ryxPg4c8vUc",
        "outputId": "bb9d1a07-914e-4d88-f811-2ea53c83feae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSxYdNWPgU19"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD1unSx30uS-"
      },
      "source": [
        "def get_data(filename):\n",
        "  file = np.genfromtxt(filename, dtype='int32', delimiter=',')\n",
        "  row_mask = (file != -1).all(axis=1) #usunięcie próbek z wartościami -1 (brak wartości pewnej cechy w datasecie)\n",
        "  file = file[row_mask, :]\n",
        "  return file"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx8CobMC35R1"
      },
      "source": [
        "def compute_chi2_stats(X, y):\n",
        "  chi2vals, pvals = chi2(X, y)\n",
        "  return chi2vals, pvals"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWvPQ1C5Hep4"
      },
      "source": [
        "def select_k_best_via_chi2(k, X, y):\n",
        "  X = SelectKBest(chi2, k).fit_transform(X, y)\n",
        "  return X"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Dc_gJcti7O"
      },
      "source": [
        "def do_cross_validation(X, y, state): #do zmiany\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=state)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEFYJrGDpR3v"
      },
      "source": [
        "def LCG(arg): # linear congruential generator\n",
        "  return (187668917 * arg + 11767183) % 2147483647\n",
        "def get_next_random(arg=0, depth=0):\n",
        "  if depth == 0:\n",
        "    return LCG(arg)\n",
        "  return get_next_random(LCG(arg), depth - 1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSJyonL0LGTc"
      },
      "source": [
        "def do_nth_cross_validation(X, y, n):\n",
        "  X_train, X_test, y_train, y_test = do_cross_validation(X, y, get_next_random(42, n))\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4SxpO7qk-2t"
      },
      "source": [
        "class NaiveBayesClassifier():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # liczymy prawdopodobienstwa a priori klas\n",
        "  def calculate_prior(self, y_train):\n",
        "    self.labels, self.counts = np.unique(y_train, return_counts=True)\n",
        "    probabilities = self.counts / np.sum(self.counts)\n",
        "    self.prior_probs = dict(zip(self.labels, probabilities))\n",
        "\n",
        "  # liczymy parametry rozkładów w klasach\n",
        "  def calculate_gaussian_parameters(self, X_train, y_train):\n",
        "    self.gauss_params = {}\n",
        "    num_of_features = X_train.shape[1]\n",
        "    for label in self.labels:\n",
        "      mean_std_for_features = []\n",
        "      for i in range(num_of_features):\n",
        "        class_indices = np.where(y_train == label)[0]\n",
        "        feature_values_for_class = X_train[class_indices, i]\n",
        "        mean_std_tuple = np.mean(feature_values_for_class), np.std(feature_values_for_class)\n",
        "        mean_std_for_features.append(mean_std_tuple)\n",
        "      self.gauss_params[label] = mean_std_for_features\n",
        "  \n",
        "  # dopasowanie modelu do danych treningowych\n",
        "  def fit(self, X_train, y_train):\n",
        "    self.calculate_prior(y_train)\n",
        "    self.calculate_gaussian_parameters(X_train, y_train)\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    num_of_samples = X_test.shape[0]\n",
        "    num_of_features = X_test.shape[1]\n",
        "    self.predicted_labels = np.zeros(num_of_samples)\n",
        "    for number, sample in enumerate(X_test):\n",
        "      prediction = self.labels[0]\n",
        "      MAP_value = float('-inf')\n",
        "      for label in self.labels:\n",
        "        Bayes_log_sum = np.log(self.prior_probs[label])\n",
        "        for i in range(num_of_features):\n",
        "          x=sample[i]\n",
        "          mean=self.gauss_params[label][i][0]\n",
        "          std=self.gauss_params[label][i][1]\n",
        "          Bayes_log_sum += -0.5*((x-mean)/std)**2 + np.log(1/(std * np.sqrt(2*np.pi)))\n",
        "        \n",
        "        if(Bayes_log_sum > MAP_value):\n",
        "          MAP_value = Bayes_log_sum\n",
        "          prediction = label\n",
        "      \n",
        "      self.predicted_labels[number] = prediction\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9YY0kaMhx5N",
        "outputId": "244cc363-27e5-45f6-a98e-a6ec46e69cd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = get_data(\"/content/drive/My Drive/Colab Notebooks/breast-cancer-wisconsin.txt\")\n",
        "X = data[:, 1:10] # macierz cech, bez id i klas\n",
        "y = data[:, 10]   # wektor klas\n",
        "chi2val, pval = compute_chi2_stats(X, y) \n",
        "print(chi2val)\n",
        "X_new  = select_k_best_via_chi2(5, X, y)\n",
        "X_train, X_test, y_train, y_test = do_nth_cross_validation(X_new, y, 7)\n",
        "\n",
        "NBC = NaiveBayesClassifier()\n",
        "NBC.fit(X_train, y_train)\n",
        "NBC.predict(X_test)\n",
        "print(y_test.shape)\n",
        "print(accuracy_score(y_test, NBC.predicted_labels))\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "library_predict = clf.predict(X_test)\n",
        "print(accuracy_score(y_test, library_predict))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 624.13570418 1370.06458731 1279.76770412  986.41787922  497.53676321\n",
            " 1729.0661744   682.97823856 1143.8667119   228.99434634]\n",
            "(342,)\n",
            "0.9649122807017544\n",
            "0.9649122807017544\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}